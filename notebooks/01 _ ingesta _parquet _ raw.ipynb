{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "252d8b55-8d85-41b1-85e4-bde9d5acb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "import gc\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, col, current_timestamp\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "691a7300-1c86-4fd6-9ef0-85ea9a518ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.0\n",
      "Spark UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "# Crear SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NYC_TLC_Ingestion_RAW\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3addf15c-0913-497f-8ce0-d16159c79018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuración de Ingesta:\n",
      "  - Base de Datos: NYC_TAXI\n",
      "  - Schema: RAW\n",
      "  - Período: 2017-2018\n",
      "  - Servicios: ['yellow', 'green']\n",
      "  - RUN_ID: 05ca0353-0649-4d90-82a3-44d0fae837d1\n",
      "  - Batch Size: 1,000,000\n"
     ]
    }
   ],
   "source": [
    "# Variables de ambiente\n",
    "SNOWFLAKE_ACCOUNT = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
    "SNOWFLAKE_USER = os.getenv(\"SNOWFLAKE_USER\")\n",
    "SNOWFLAKE_PASSWORD = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
    "SNOWFLAKE_WAREHOUSE = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "SNOWFLAKE_DATABASE = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
    "SNOWFLAKE_ROLE = os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "SNOWFLAKE_SCHEMA_RAW = os.getenv(\"SNOWFLAKE_SCHEMA_RAW\", \"RAW\")\n",
    "\n",
    "START_YEAR = 2017\n",
    "END_YEAR = 2018\n",
    "SERVICES = os.getenv(\"SERVICES\", \"yellow,green\").split(\",\")\n",
    "BASE_URL = os.getenv(\"BASE_URL\", \"https://d37ci6vzurychx.cloudfront.net/trip-data\")\n",
    "RUN_ID = os.getenv(\"RUN_ID\", str(uuid.uuid4()))\n",
    "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", 1_000_000))\n",
    "\n",
    "print(f\"\\nConfiguración de Ingesta:\")\n",
    "print(f\"  - Base de Datos: {SNOWFLAKE_DATABASE}\")\n",
    "print(f\"  - Schema: {SNOWFLAKE_SCHEMA_RAW}\")\n",
    "print(f\"  - Período: {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"  - Servicios: {SERVICES}\")\n",
    "print(f\"  - RUN_ID: {RUN_ID}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376b197-b9a2-41fd-88dd-a9728a8cd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probando conexión a Snowflake...\n",
      "Conectado a Snowflake versión: 9.37.0\n",
      "Database: NYC_TAXI, Schema: RAW\n"
     ]
    }
   ],
   "source": [
    "def get_snowflake_conn():\n",
    "    return snowflake.connector.connect(\n",
    "        user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "        password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "        account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "        warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "        database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "        schema=os.getenv(\"SNOWFLAKE_SCHEMA_RAW\", \"RAW\"),\n",
    "        role=os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "        client_session_keep_alive=True,\n",
    "    )\n",
    "\n",
    "print(\"\\nProbando conexión a Snowflake...\")\n",
    "try:\n",
    "    _conn = get_snowflake_conn()\n",
    "    _cur = _conn.cursor()\n",
    "    _cur.execute(\"SELECT CURRENT_VERSION()\")\n",
    "    version = _cur.fetchone()[0]\n",
    "    _cur.execute(f\"SELECT CURRENT_DATABASE(), CURRENT_SCHEMA()\")\n",
    "    db_info = _cur.fetchone()\n",
    "    print(f\"Conectado a Snowflake versión: {version}\")\n",
    "    print(f\"Database: {db_info[0]}, Schema: {db_info[1]}\")\n",
    "    _cur.close()\n",
    "    _conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error de conexión: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d34aacf4-0bd2-4258-a8c9-18c6b609f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(service: str, year: int, month: int) -> str:\n",
    "    \"\"\"Construye URL del archivo Parquet\"\"\"\n",
    "    return f\"{BASE_URL}/{service}_tripdata_{year}-{month:02d}.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4baec969-bd11-4877-b3bf-72b78619ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables_if_not_exist(conn, service: str):\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    if service == \"yellow\":\n",
    "        table_name = \"YELLOW_TAXIS\"\n",
    "        audit_table = \"AUDIT_YELLOW\"\n",
    "        \n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {SNOWFLAKE_SCHEMA_RAW}.{table_name} (\n",
    "            VENDORID NUMBER,\n",
    "            TPEP_PICKUP_DATETIME TIMESTAMP_NTZ,\n",
    "            TPEP_DROPOFF_DATETIME TIMESTAMP_NTZ,\n",
    "            PASSENGER_COUNT NUMBER,\n",
    "            TRIP_DISTANCE FLOAT,\n",
    "            RATECODEID NUMBER,\n",
    "            STORE_AND_FWD_FLAG VARCHAR(1),\n",
    "            PULOCATIONID NUMBER,\n",
    "            DOLOCATIONID NUMBER,\n",
    "            PAYMENT_TYPE NUMBER,\n",
    "            FARE_AMOUNT FLOAT,\n",
    "            EXTRA FLOAT,\n",
    "            MTA_TAX FLOAT,\n",
    "            TIP_AMOUNT FLOAT,\n",
    "            TOLLS_AMOUNT FLOAT,\n",
    "            IMPROVEMENT_SURCHARGE FLOAT,\n",
    "            TOTAL_AMOUNT FLOAT,\n",
    "            CONGESTION_SURCHARGE FLOAT,\n",
    "            AIRPORT_FEE FLOAT,\n",
    "            CBD_CONGESTION_FEE FLOAT,\n",
    "            RUN_ID STRING,\n",
    "            INGESTED_AT_UTC TIMESTAMP_NTZ,\n",
    "            SOURCE_YEAR NUMBER,\n",
    "            SOURCE_MONTH NUMBER,\n",
    "            CHUNK_ID VARCHAR(50),\n",
    "            PRIMARY KEY (TPEP_PICKUP_DATETIME, TPEP_DROPOFF_DATETIME, PULOCATIONID, DOLOCATIONID)\n",
    "        );\n",
    "        \"\"\"\n",
    "    else:  # green\n",
    "        table_name = \"GREEN_TAXIS\"\n",
    "        audit_table = \"AUDIT_GREEN\"\n",
    "        \n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {SNOWFLAKE_SCHEMA_RAW}.{table_name} (\n",
    "            VENDORID NUMBER,\n",
    "            LPEP_PICKUP_DATETIME TIMESTAMP_NTZ,\n",
    "            LPEP_DROPOFF_DATETIME TIMESTAMP_NTZ,\n",
    "            STORE_AND_FWD_FLAG VARCHAR(1),\n",
    "            RATECODEID NUMBER,\n",
    "            PULOCATIONID NUMBER,\n",
    "            DOLOCATIONID NUMBER,\n",
    "            PASSENGER_COUNT NUMBER,\n",
    "            TRIP_DISTANCE FLOAT,\n",
    "            FARE_AMOUNT FLOAT,\n",
    "            EXTRA FLOAT,\n",
    "            MTA_TAX FLOAT,\n",
    "            TIP_AMOUNT FLOAT,\n",
    "            TOLLS_AMOUNT FLOAT,\n",
    "            EHAIL_FEE FLOAT,\n",
    "            IMPROVEMENT_SURCHARGE FLOAT,\n",
    "            TOTAL_AMOUNT FLOAT,\n",
    "            PAYMENT_TYPE NUMBER,\n",
    "            TRIP_TYPE NUMBER,\n",
    "            CONGESTION_SURCHARGE FLOAT,\n",
    "            CBD_CONGESTION_FEE FLOAT,\n",
    "            AIRPORT_FEE FLOAT,\n",
    "            RUN_ID STRING,\n",
    "            INGESTED_AT_UTC TIMESTAMP_NTZ,\n",
    "            SOURCE_YEAR NUMBER,\n",
    "            SOURCE_MONTH NUMBER,\n",
    "            CHUNK_ID VARCHAR(50),\n",
    "            PRIMARY KEY (LPEP_PICKUP_DATETIME, LPEP_DROPOFF_DATETIME, PULOCATIONID, DOLOCATIONID)\n",
    "        );\n",
    "        \"\"\"\n",
    "    \n",
    "    cur.execute(create_table_sql)\n",
    "    print(f\"Tabla {table_name} verificada/creada\")\n",
    "    \n",
    "    # Crear tabla de auditoría\n",
    "    create_audit_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {SNOWFLAKE_SCHEMA_RAW}.{audit_table} (\n",
    "        SERVICE STRING,\n",
    "        YEAR NUMBER,\n",
    "        MONTH NUMBER,\n",
    "        STATUS STRING,\n",
    "        ROW_COUNT NUMBER,\n",
    "        ERROR_MESSAGE STRING,\n",
    "        RUN_ID STRING,\n",
    "        INGESTED_AT_UTC TIMESTAMP_NTZ\n",
    "    );\n",
    "    \"\"\"\n",
    "    cur.execute(create_audit_sql)\n",
    "    print(f\"Tabla de auditoría {audit_table} verificada/creada\")\n",
    "    \n",
    "    cur.close()\n",
    "    return table_name, audit_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "100faf7f-e167-438f-9a5d-c70ffa5636ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_already_loaded(conn, audit_table: str, service: str, year: int, month: int) -> bool:\n",
    "    query = f\"\"\"\n",
    "    SELECT 1\n",
    "    FROM {SNOWFLAKE_SCHEMA_RAW}.{audit_table}\n",
    "    WHERE SERVICE = %s\n",
    "      AND YEAR = %s\n",
    "      AND MONTH = %s\n",
    "      AND STATUS = 'ok'\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query, (service, year, month))\n",
    "    result = cur.fetchone()\n",
    "    cur.close()\n",
    "    return result is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09e59f85-f4f1-4045-9359-a7dfbc774267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_service(service: str, start_year: int, end_year: int):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"INICIANDO INGESTA: {service.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    conn = get_snowflake_conn()\n",
    "    table_name, audit_table = create_tables_if_not_exist(conn, service)\n",
    "    \n",
    "    ingested_at = datetime.utcnow()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Accept\": \"application/octet-stream\",\n",
    "    }\n",
    "    \n",
    "    total_months_processed = 0\n",
    "    total_months_skipped = 0\n",
    "    total_rows_ingested = 0\n",
    "    \n",
    "    try:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            for month in range(1, 13):\n",
    "                # Verificar idempotencia\n",
    "                if month_already_loaded(conn, audit_table, service, year, month):\n",
    "                    print(f\"[SKIP] {service} {year}-{month:02d} ya cargado (idempotencia)\")\n",
    "                    total_months_skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                url = build_url(service, year, month)\n",
    "                print(f\"\\n[{year}-{month:02d}] Descargando desde: {url}\")\n",
    "                \n",
    "                row_count = 0\n",
    "                status = \"ok\"\n",
    "                error_msg = None\n",
    "                \n",
    "                try:\n",
    "                    # Descargar archivo\n",
    "                    resp = requests.get(url, headers=headers, timeout=120)\n",
    "                    \n",
    "                    if resp.status_code == 404 or resp.status_code == 403:\n",
    "                        print(f\"[{year}-{month:02d}] Archivo no disponible (HTTP {resp.status_code})\")\n",
    "                        status = \"skip\"\n",
    "                        error_msg = f\"Archivo no disponible (HTTP {resp.status_code})\"\n",
    "                        \n",
    "                        # Registrar en auditoría\n",
    "                        cur = conn.cursor()\n",
    "                        cur.execute(f\"\"\"\n",
    "                            INSERT INTO {SNOWFLAKE_SCHEMA_RAW}.{audit_table}\n",
    "                            (SERVICE, YEAR, MONTH, STATUS, ROW_COUNT, ERROR_MESSAGE, RUN_ID, INGESTED_AT_UTC)\n",
    "                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                        \"\"\", (service, year, month, status, 0, error_msg, RUN_ID, ingested_at))\n",
    "                        cur.close()\n",
    "                        total_months_skipped += 1\n",
    "                        continue\n",
    "                    \n",
    "                    resp.raise_for_status()\n",
    "                    \n",
    "                    # Leer Parquet en chunks\n",
    "                    parquet_file = pq.ParquetFile(BytesIO(resp.content))\n",
    "                    total_rows = parquet_file.metadata.num_rows\n",
    "                    total_batches = (total_rows // BATCH_SIZE) + (1 if total_rows % BATCH_SIZE else 0)\n",
    "                    \n",
    "                    print(f\"[{year}-{month:02d}] Total filas: {total_rows:,} en {total_batches} batch(es)\")\n",
    "                    \n",
    "                    # Procesar por batches\n",
    "                    for i, batch in enumerate(parquet_file.iter_batches(batch_size=BATCH_SIZE), start=1):\n",
    "                        df = batch.to_pandas()\n",
    "                        \n",
    "                        # Agregar metadatos\n",
    "                        df[\"RUN_ID\"] = RUN_ID\n",
    "                        df[\"INGESTED_AT_UTC\"] = ingested_at\n",
    "                        df[\"SOURCE_YEAR\"] = year\n",
    "                        df[\"SOURCE_MONTH\"] = month\n",
    "                        df[\"CHUNK_ID\"] = f\"{i}/{total_batches}\"\n",
    "                        \n",
    "                        # Normalizar nombres de columnas\n",
    "                        df = df.rename(columns=str.upper)\n",
    "                        \n",
    "                        # Convertir timestamps\n",
    "                        timestamp_cols = []\n",
    "                        if service == \"yellow\":\n",
    "                            timestamp_cols = [\"TPEP_PICKUP_DATETIME\", \"TPEP_DROPOFF_DATETIME\"]\n",
    "                        else:\n",
    "                            timestamp_cols = [\"LPEP_PICKUP_DATETIME\", \"LPEP_DROPOFF_DATETIME\"]\n",
    "                        \n",
    "                        timestamp_cols.append(\"INGESTED_AT_UTC\")\n",
    "                        \n",
    "                        for col in timestamp_cols:\n",
    "                            if col in df.columns:\n",
    "                                df[col] = pd.to_datetime(df[col], errors=\"coerce\").dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        \n",
    "                        # Escribir a Snowflake\n",
    "                        success, nchunks, nrows, _ = write_pandas(\n",
    "                            conn,\n",
    "                            df,\n",
    "                            table_name=table_name,\n",
    "                            auto_create_table=False,\n",
    "                            overwrite=False,\n",
    "                            quote_identifiers=True,\n",
    "                        )\n",
    "                        \n",
    "                        row_count += len(df)\n",
    "                        print(f\"Batch {i}/{total_batches}: {len(df):,} filas escritas (acum: {row_count:,})\")\n",
    "                        \n",
    "                        # Limpiar memoria\n",
    "                        del df\n",
    "                        gc.collect()\n",
    "                        time.sleep(0.5)\n",
    "                    \n",
    "                    # Registrar éxito en auditoría\n",
    "                    cur = conn.cursor()\n",
    "                    cur.execute(f\"\"\"\n",
    "                        INSERT INTO {SNOWFLAKE_SCHEMA_RAW}.{audit_table}\n",
    "                        (SERVICE, YEAR, MONTH, STATUS, ROW_COUNT, ERROR_MESSAGE, RUN_ID, INGESTED_AT_UTC)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (service, year, month, status, row_count, None, RUN_ID, ingested_at))\n",
    "                    cur.close()\n",
    "                    \n",
    "                    total_months_processed += 1\n",
    "                    total_rows_ingested += row_count\n",
    "                    print(f\"[{year}-{month:02d}] Completado: {row_count:,} filas ingestadas\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_msg = str(e)\n",
    "                    print(f\"[{year}-{month:02d}] ERROR: {error_msg}\")\n",
    "                    \n",
    "                    # Registrar fallo en auditoría\n",
    "                    cur = conn.cursor()\n",
    "                    cur.execute(f\"\"\"\n",
    "                        INSERT INTO {SNOWFLAKE_SCHEMA_RAW}.{audit_table}\n",
    "                        (SERVICE, YEAR, MONTH, STATUS, ROW_COUNT, ERROR_MESSAGE, RUN_ID, INGESTED_AT_UTC)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (service, year, month, \"fail\", 0, error_msg, RUN_ID, ingested_at))\n",
    "                    cur.close()\n",
    "                \n",
    "                time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Resumen\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RESUMEN INGESTA {service.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Meses procesados: {total_months_processed}\")\n",
    "        print(f\"Meses omitidos: {total_months_skipped}\")\n",
    "        print(f\"Total filas ingestadas: {total_rows_ingested:,}\")\n",
    "        print(f\"RUN_ID: {RUN_ID}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0e72436-8df3-4673-9d59-54591090f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO PROCESO DE INGESTA COMPLETA\n",
      "Servicios a procesar: ['yellow', 'green']\n",
      "\n",
      "================================================================================\n",
      "INICIANDO INGESTA: YELLOW\n",
      "================================================================================\n",
      "Tabla YELLOW_TAXIS verificada/creada\n",
      "Tabla de auditoría AUDIT_YELLOW verificada/creada\n",
      "[SKIP] yellow 2017-01 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-02 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-03 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-04 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-05 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-06 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-07 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-08 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-09 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-10 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-11 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2017-12 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-01 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-02 ya cargado (idempotencia)\n",
      "\n",
      "[2018-03] Descargando desde: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-03.parquet\n",
      "[2018-03] Total filas: 9,431,289 en 10 batch(es)\n",
      "Batch 1/10: 1,000,000 filas escritas (acum: 1,000,000)\n",
      "Batch 2/10: 1,000,000 filas escritas (acum: 2,000,000)\n",
      "Batch 3/10: 1,000,000 filas escritas (acum: 3,000,000)\n",
      "Batch 4/10: 1,000,000 filas escritas (acum: 4,000,000)\n",
      "Batch 5/10: 1,000,000 filas escritas (acum: 5,000,000)\n",
      "Batch 6/10: 1,000,000 filas escritas (acum: 6,000,000)\n",
      "Batch 7/10: 1,000,000 filas escritas (acum: 7,000,000)\n",
      "Batch 8/10: 1,000,000 filas escritas (acum: 8,000,000)\n",
      "Batch 9/10: 1,000,000 filas escritas (acum: 9,000,000)\n",
      "Batch 10/10: 431,289 filas escritas (acum: 9,431,289)\n",
      "[2018-03] Completado: 9,431,289 filas ingestadas\n",
      "[SKIP] yellow 2018-04 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-05 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-06 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-07 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-08 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-09 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-10 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-11 ya cargado (idempotencia)\n",
      "[SKIP] yellow 2018-12 ya cargado (idempotencia)\n",
      "\n",
      "================================================================================\n",
      "RESUMEN INGESTA YELLOW\n",
      "================================================================================\n",
      "Meses procesados: 1\n",
      "Meses omitidos: 23\n",
      "Total filas ingestadas: 9,431,289\n",
      "RUN_ID: 05ca0353-0649-4d90-82a3-44d0fae837d1\n",
      "\n",
      "================================================================================\n",
      "INICIANDO INGESTA: GREEN\n",
      "================================================================================\n",
      "Tabla GREEN_TAXIS verificada/creada\n",
      "Tabla de auditoría AUDIT_GREEN verificada/creada\n",
      "[SKIP] green 2017-01 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-02 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-03 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-04 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-05 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-06 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-07 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-08 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-09 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-10 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-11 ya cargado (idempotencia)\n",
      "[SKIP] green 2017-12 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-01 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-02 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-03 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-04 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-05 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-06 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-07 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-08 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-09 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-10 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-11 ya cargado (idempotencia)\n",
      "[SKIP] green 2018-12 ya cargado (idempotencia)\n",
      "\n",
      "================================================================================\n",
      "RESUMEN INGESTA GREEN\n",
      "================================================================================\n",
      "Meses procesados: 0\n",
      "Meses omitidos: 24\n",
      "Total filas ingestadas: 0\n",
      "RUN_ID: 05ca0353-0649-4d90-82a3-44d0fae837d1\n",
      "\n",
      "================================================================================\n",
      "PROCESO DE INGESTA COMPLETADO\n",
      "================================================================================\n",
      "\n",
      " VERIFICACIÓN FINAL: Conteo de registros\n",
      "\n",
      "YELLOW - Distribución por año/mes:\n",
      "  2015-01: 12,741,035 filas\n",
      "  2015-02: 12,442,394 filas\n",
      "  2015-03: 13,342,951 filas\n",
      "  2015-04: 13,063,758 filas\n",
      "  2015-05: 13,157,677 filas\n",
      "  2015-06: 12,324,936 filas\n",
      "  2015-07: 11,559,666 filas\n",
      "  2015-08: 11,123,123 filas\n",
      "  2015-09: 11,218,122 filas\n",
      "  2015-10: 12,307,333 filas\n",
      "  2015-11: 11,305,240 filas\n",
      "  2015-12: 11,452,996 filas\n",
      "  2016-01: 10,905,067 filas\n",
      "  2016-02: 11,375,412 filas\n",
      "  2016-03: 12,203,824 filas\n",
      "  2016-04: 11,927,996 filas\n",
      "  2016-05: 11,832,049 filas\n",
      "  2016-06: 11,131,645 filas\n",
      "  2016-07: 10,294,080 filas\n",
      "  2016-08: 9,942,263 filas\n",
      "  2016-09: 10,116,018 filas\n",
      "  2016-10: 10,854,626 filas\n",
      "  2016-11: 10,102,128 filas\n",
      "  2016-12: 10,446,697 filas\n",
      "  2017-01: 9,710,820 filas\n",
      "  2017-02: 9,169,775 filas\n",
      "  2017-03: 10,295,441 filas\n",
      "  2017-04: 10,047,135 filas\n",
      "  2017-05: 10,102,127 filas\n",
      "  2017-06: 9,656,993 filas\n",
      "  2017-07: 8,588,486 filas\n",
      "  2017-08: 8,422,153 filas\n",
      "  2017-09: 8,945,421 filas\n",
      "  2017-10: 9,768,672 filas\n",
      "  2017-11: 9,284,803 filas\n",
      "  2017-12: 9,508,501 filas\n",
      "  2018-01: 8,760,687 filas\n",
      "  2018-02: 8,492,819 filas\n",
      "  2018-03: 9,431,289 filas\n",
      "  2018-04: 9,306,216 filas\n",
      "  2018-05: 9,224,788 filas\n",
      "  2018-06: 8,714,667 filas\n",
      "  2018-07: 7,851,143 filas\n",
      "  2018-08: 7,855,040 filas\n",
      "  2018-09: 8,049,094 filas\n",
      "  2018-10: 8,834,520 filas\n",
      "  2018-11: 8,155,449 filas\n",
      "  2018-12: 8,195,675 filas\n",
      "\n",
      "GREEN - Distribución por año/mes:\n",
      "  2015-01: 1,508,493 filas\n",
      "  2015-02: 1,574,830 filas\n",
      "  2015-03: 1,722,574 filas\n",
      "  2015-04: 1,664,394 filas\n",
      "  2015-05: 1,786,848 filas\n",
      "  2015-06: 1,638,868 filas\n",
      "  2015-07: 1,541,671 filas\n",
      "  2015-08: 1,532,343 filas\n",
      "  2015-09: 1,494,927 filas\n",
      "  2015-10: 1,630,536 filas\n",
      "  2015-11: 1,529,984 filas\n",
      "  2015-12: 1,608,297 filas\n",
      "  2016-01: 1,445,292 filas\n",
      "  2016-02: 1,510,722 filas\n",
      "  2016-03: 1,576,393 filas\n",
      "  2016-04: 1,543,926 filas\n",
      "  2016-05: 1,536,979 filas\n",
      "  2016-06: 1,404,727 filas\n",
      "  2016-07: 1,332,510 filas\n",
      "  2016-08: 1,247,675 filas\n",
      "  2016-09: 1,162,373 filas\n",
      "  2016-10: 1,252,572 filas\n",
      "  2016-11: 1,148,214 filas\n",
      "  2016-12: 1,224,158 filas\n",
      "  2017-01: 1,069,565 filas\n",
      "  2017-02: 1,022,313 filas\n",
      "  2017-03: 1,157,827 filas\n",
      "  2017-04: 1,080,844 filas\n",
      "  2017-05: 1,059,463 filas\n",
      "  2017-06: 976,467 filas\n",
      "  2017-07: 914,783 filas\n",
      "  2017-08: 867,407 filas\n",
      "  2017-09: 882,464 filas\n",
      "  2017-10: 925,737 filas\n",
      "  2017-11: 874,173 filas\n",
      "  2017-12: 906,016 filas\n",
      "  2018-01: 792,744 filas\n",
      "  2018-02: 769,197 filas\n",
      "  2018-03: 836,246 filas\n",
      "  2018-04: 799,383 filas\n",
      "  2018-05: 796,552 filas\n",
      "  2018-06: 738,546 filas\n",
      "  2018-07: 684,374 filas\n",
      "  2018-08: 675,815 filas\n",
      "  2018-09: 682,032 filas\n",
      "  2018-10: 731,888 filas\n",
      "  2018-11: 673,287 filas\n",
      "  2018-12: 719,654 filas\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nINICIANDO PROCESO DE INGESTA COMPLETA\")\n",
    "print(f\"Servicios a procesar: {SERVICES}\")\n",
    "\n",
    "for service in SERVICES:\n",
    "    service = service.strip().lower()\n",
    "    if service not in [\"yellow\", \"green\"]:\n",
    "        print(f\"Servicio '{service}' no válido. Solo se permiten 'yellow' o 'green'\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        ingest_service(service, START_YEAR, END_YEAR)\n",
    "    except Exception as e:\n",
    "        print(f\"Error crítico en servicio {service}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PROCESO DE INGESTA COMPLETADO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# %% Verificación final: Conteo por tabla\n",
    "print(\"\\n VERIFICACIÓN FINAL: Conteo de registros\")\n",
    "conn = get_snowflake_conn()\n",
    "cur = conn.cursor()\n",
    "\n",
    "for service in SERVICES:\n",
    "    service = service.strip().lower()\n",
    "    if service == \"yellow\":\n",
    "        table = \"YELLOW_TAXIS\"\n",
    "    elif service == \"green\":\n",
    "        table = \"GREEN_TAXIS\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT \n",
    "                SOURCE_YEAR,\n",
    "                SOURCE_MONTH,\n",
    "                COUNT(*) as row_count\n",
    "            FROM {SNOWFLAKE_SCHEMA_RAW}.{table}\n",
    "            GROUP BY SOURCE_YEAR, SOURCE_MONTH\n",
    "            ORDER BY SOURCE_YEAR, SOURCE_MONTH\n",
    "        \"\"\")\n",
    "        \n",
    "        results = cur.fetchall()\n",
    "        print(f\"\\n{service.upper()} - Distribución por año/mes:\")\n",
    "        for row in results:\n",
    "            print(f\"  {row[0]}-{row[1]:02d}: {row[2]:,} filas\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error verificando {service}: {e}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
